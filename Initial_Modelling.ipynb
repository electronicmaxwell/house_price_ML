{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Modelling for Ames Iowa Housing Dataset\n",
    "\n",
    "## Goals\n",
    "- Train models with minimally processed dataset to get understand of baseline performance\n",
    "- Identify which models seem more promising for given dataset\n",
    "\n",
    "## Notes\n",
    "- csv files to train initial modelling have been overwritten. Can be achieved by only running preprocess_data() function from Data_Preprocessing.ipynb\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "RANDOM_SEED = 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_processed.csv')\n",
    "test = pd.read_csv('test_processed.csv')\n",
    "\n",
    "features = train.iloc[:, :-1]\n",
    "target = train.iloc[:, -1]\n",
    "\n",
    "target_transformed = np.log1p(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 244), (1460,), (1459, 244))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, target.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "ridge = make_pipeline(RobustScaler(), RidgeCV(cv=kfolds))\n",
    "lasso = make_pipeline(RobustScaler(), LassoCV(random_state=RANDOM_SEED, cv=kfolds))\n",
    "elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(cv=kfolds))                                \n",
    "svr = make_pipeline(RobustScaler(), SVR())\n",
    "rfr = RandomForestRegressor(random_state=RANDOM_SEED)\n",
    "gbr = GradientBoostingRegressor(random_state=RANDOM_SEED)\n",
    "lightgbm = LGBMRegressor(random_state=RANDOM_SEED)\n",
    "xgboost = XGBRegressor(seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Modelling\n",
    "- No hyperparameter tuning\n",
    "- Target Transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Ridge...\n",
      "Ridge - Training completed in 1.41 seconds.\n",
      "--------------------------------------------------\n",
      "Training Lasso...\n",
      "Lasso - Training completed in 1.98 seconds.\n",
      "--------------------------------------------------\n",
      "Training ElasticNet...\n",
      "ElasticNet - Training completed in 2.10 seconds.\n",
      "--------------------------------------------------\n",
      "Training SVR...\n",
      "SVR - Training completed in 1.14 seconds.\n",
      "--------------------------------------------------\n",
      "Training RandomForest...\n",
      "RandomForest - Training completed in 10.46 seconds.\n",
      "--------------------------------------------------\n",
      "Training GradientBoostingRegressor...\n",
      "GradientBoostingRegressor - Training completed in 3.84 seconds.\n",
      "--------------------------------------------------\n",
      "Training LightGBM...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3327\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 163\n",
      "[LightGBM] [Info] Start training from score 12.022547\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3333\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 164\n",
      "[LightGBM] [Info] Start training from score 12.023431\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3340\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 163\n",
      "[LightGBM] [Info] Start training from score 12.026992\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3342\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 164\n",
      "[LightGBM] [Info] Start training from score 12.025121\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3332\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 164\n",
      "[LightGBM] [Info] Start training from score 12.021541\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3335\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 163\n",
      "[LightGBM] [Info] Start training from score 12.024065\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3322\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 163\n",
      "[LightGBM] [Info] Start training from score 12.024495\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3254\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 164\n",
      "[LightGBM] [Info] Start training from score 12.023536\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3328\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 163\n",
      "[LightGBM] [Info] Start training from score 12.022682\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3251\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 163\n",
      "[LightGBM] [Info] Start training from score 12.026165\n",
      "LightGBM - Training completed in 5.94 seconds.\n",
      "--------------------------------------------------\n",
      "Training XGBoost...\n",
      "XGBoost - Training completed in 2.55 seconds.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean RMSE</th>\n",
       "      <th>Std RMSE</th>\n",
       "      <th>Training Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.128806</td>\n",
       "      <td>0.021071</td>\n",
       "      <td>3.841038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.128983</td>\n",
       "      <td>0.019724</td>\n",
       "      <td>5.939006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.137092</td>\n",
       "      <td>0.040518</td>\n",
       "      <td>1.408832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.141038</td>\n",
       "      <td>0.017799</td>\n",
       "      <td>2.547016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.142217</td>\n",
       "      <td>0.022442</td>\n",
       "      <td>10.463284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.148488</td>\n",
       "      <td>0.043025</td>\n",
       "      <td>2.101672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.148554</td>\n",
       "      <td>0.043268</td>\n",
       "      <td>1.982795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.345249</td>\n",
       "      <td>0.032728</td>\n",
       "      <td>1.141990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Mean RMSE  Std RMSE  Training Time (s)\n",
       "5  GradientBoostingRegressor   0.128806  0.021071           3.841038\n",
       "6                   LightGBM   0.128983  0.019724           5.939006\n",
       "0                      Ridge   0.137092  0.040518           1.408832\n",
       "7                    XGBoost   0.141038  0.017799           2.547016\n",
       "4               RandomForest   0.142217  0.022442          10.463284\n",
       "2                 ElasticNet   0.148488  0.043025           2.101672\n",
       "1                      Lasso   0.148554  0.043268           1.982795\n",
       "3                        SVR   0.345249  0.032728           1.141990"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "scoring = 'neg_mean_squared_error'\n",
    "models = {\n",
    "    'Ridge': ridge,\n",
    "    'Lasso': lasso,\n",
    "    'ElasticNet': elasticnet,\n",
    "    'SVR': svr,\n",
    "    'RandomForest': rfr,\n",
    "    'GradientBoostingRegressor': gbr,\n",
    "    'LightGBM': lightgbm,\n",
    "    'XGBoost': xgboost\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    start_time = time.time()\n",
    "    scores = cross_val_score(model, features, target_transformed, cv=kfolds, scoring=scoring)\n",
    "    \n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    mean_rmse = np.mean(rmse_scores)\n",
    "    std_rmse = np.std(rmse_scores)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    results[name] = {\n",
    "        'Mean RMSE': mean_rmse,\n",
    "        'Std RMSE': std_rmse,\n",
    "        'Training Time (s)': training_time\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} - Training completed in {training_time:.2f} seconds.\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "results_df = pd.DataFrame(results).T.reset_index()\n",
    "results_df.columns = ['Model', 'Mean RMSE', 'Std RMSE', 'Training Time (s)']\n",
    "results_df.sort_values(by='Mean RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Initial modelling of data is promising, all models perform reasonable well on data\n",
    "- There is lots of possibility for feature engineering\n",
    "- Models need hyperparameter tuning\n",
    "- I'm not well educated on the topic but combining predictions from several models or using a stacking algorithm could further improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3430\n",
      "[LightGBM] [Info] Number of data points in the train set: 1460, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score 12.024057\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>125638.467587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>161710.610146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>191458.537926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>189480.428186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>190516.485793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  125638.467587\n",
       "1  1462  161710.610146\n",
       "2  1463  191458.537926\n",
       "3  1464  189480.428186\n",
       "4  1465  190516.485793"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightgbm.fit(features, target_transformed)\n",
    "scaled_predictions = np.expm1(lightgbm.predict(test))\n",
    "submission = pd.DataFrame({\n",
    "    'Id': list(range(1461, 2920)),\n",
    "    'SalePrice': scaled_predictions\n",
    "})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('first_submission_lgbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- LGBM performs significantly better on untransformed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
